{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePrediction:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model =  models.inception_v3(pretrained=True)\n",
    "        self.model.eval()\n",
    "        self.load_class_labels()\n",
    "        \n",
    "    \n",
    "    def load_class_labels(self):\n",
    "        try:\n",
    "            with open(\"imagenet_class_index.json\") as f:\n",
    "                class_idx = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "            response = requests.get(url)\n",
    "            class_names = response.json()\n",
    "            class_idx = {str(i): [str(i), name] for i, name in enumerate(class_names)}\n",
    "            with open(\"imagenet_class_index.json\", \"w\") as f:\n",
    "                json.dump(class_idx,f)\n",
    "        \n",
    "    def preprocess_image(self,image):\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(299),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            \n",
    "        ])\n",
    "        \n",
    "        return preprocess(image)\n",
    "    \n",
    "    \n",
    "                \n",
    "    def predict_image(self,image_path,top_k=1):\n",
    "        if image_path.startswith((\"http://\",\"https://\")):\n",
    "            response = requests.get(image_path)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "            \n",
    "        input_tensor = self.preprocess_image(image)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_batch)\n",
    "        \n",
    "        \n",
    "        return np.argmax(output)\n",
    "    \n",
    "    def result(self,image):\n",
    "        prediction = image_predicator.predict_image(image)\n",
    "        #print(f\"Prediction: {prediction}\")\n",
    "\n",
    "        return prediction, data[str(prediction.item())][1]\n",
    "#else:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\software\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(934), 'hot dog')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "image_predicator = ImagePrediction()\n",
    "print(image_predicator.result(\"https://nypost.com/wp-content/uploads/sites/2/2016/07/hot-dog-2.jpg?quality=90&strip=all&w=1280\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
